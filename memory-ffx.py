from pathlib import Path

import numpy as np
import pandas as pd
import nibabel as nib
import matplotlib.pyplot as plt
from nilearn import glm, image, plotting
from nilearn.glm.first_level import FirstLevelModel
from nilearn.glm.contrasts import compute_fixed_effects
from nilearn.interfaces.fmriprep import load_confounds_strategy


def _label_cond(row):
    """
    Parameters
    ----------
    row : pd.Series

    # TODO : Double-check that these are being correctly generated
    """
    if not row["error"] and row["condition"] == "unseen":
        cond = "correct_rej"
    elif not row["error"] and row["condition"] == "seen":
        cond = "hit"
    elif row["error"] is True and row["condition"] == "unseen":
        cond = "false_alarm"
    elif row["error"] is True and row["condition"] == "seen":
        cond = "miss"
    else:
        cond = pd.NA
    return cond


def _get_files(subject, data_dir):
    """
    Parameters
    ----------
    subject : str
        CNeuroMod subject for analysis. Must be in
        ['sub-01', 'sub-02', 'sub-03']
    data_dir : str or Pathlike
        Location on disk with CNeuroMod things.fmriprep dataset.
        Assumes this has previously been installed with datalad.

    Returns
    -------
    img_files : list
        List of fMRIPrep-preprocessed NifTI image files for the
        given subject, T1w space
    events : list
        List of events files for each subject, used to generate
        design matrices
    masks : list
        List of brain masks generated by fMRIPrep for each run,
        T1w space
    """
    img_files = sorted(
        Path(data_dir, "things.fmriprep", "sub-01").rglob(
            "*space-T1w_desc-preproc_bold.nii.gz"
        )
    )
    masks = sorted(
        Path(data_dir, "things.fmriprep", "sub-01").rglob(
            "*space-T1w_desc-brain_mask.nii.gz"
        )
    )

    # only grab events with three digit ses nums ; indicates corrected
    events = sorted(
        Path(data_dir, "things.fmriprep", "sourcedata", "things", "sub-01").rglob(
            "*ses-???_*events.tsv"
        )
    )

    # drop ses-01 / ses-001 from images, masks, events
    img_files = list(filter(lambda i: ("ses-01" not in str(i)), img_files))
    masks = list(filter(lambda m: ("ses-01" not in str(m)), masks))
    events = list(filter(lambda e: ("ses-001" not in str(e)), events))

    if subject == "sub-01":
        # exceptionally for sub-01, ses-030, run-01 had no responses ;
        # need to additionally filter these out
        img_files = list(
            filter(
                lambda i: ("sub-01_ses-30_task-things_run-1" not in str(i)), img_files
            )
        )
        masks = list(
            filter(lambda m: ("sub-01_ses-30_task-things_run-1" not in str(m)), masks)
        )

    return img_files, events, masks


def _gen_stats_img(img, event, mask, t_r=1.49, smoothing_fwhm=5, return_x_matrix=False):
    """
    Parameters
    ----------
    img : str or Pathlike
    event : str or Pathlike
    mask : str or Pathlik
    t_r : float
        Default 1.49
    smoothing_fwhm : int
        Default 5
    return_x_matrix : Bool
        Default False

    Returns
    -------
    stats_img : dict
    design_matrix : pd.DataFrame, optional
    """
    # load in events files and create memory conditions
    # based on performance
    df = pd.read_csv(event, sep="\t")
    df["memory_cond"] = df.apply(_label_cond, axis=1)
    memory_events = pd.DataFrame(
        {"trial_type": df.memory_cond, "onset": df.onset, "duration": df.duration}
    )

    confounds, _ = load_confounds_strategy(
        str(img),
        denoise_strategy="compcor",
        compcor="temporal_anat_combined",
        n_compcor=10,
    )

    n_scans = nib.load(img).shape[-1]
    frame_times = np.arange(n_scans) * t_r

    # generate design matrices
    # TODO: Select sensible choices here
    design_matrix = glm.first_level.make_first_level_design_matrix(
        frame_times=frame_times,
        events=memory_events,
        # drift_model="polynomial",
        # drift_order=3,
        add_regs=confounds,
        add_reg_names=confounds.columns,
        hrf_model="glover",
    )

    fmri_glm = FirstLevelModel(t_r=t_r, mask_img=mask, smoothing_fwhm=smoothing_fwhm)
    fmri_glm = fmri_glm.fit(img, design_matrices=design_matrix)

    contrast_val = (design_matrix.columns == "hit") * 1.0 - (
        design_matrix.columns == "correct_rej"
    )
    stats_img = fmri_glm.compute_contrast(contrast_val, output_type="all")

    if return_x_matrix:
        return stats_img, design_matrix
    else:
        return stats_img


if __name__ == "__main__":
    datadir = Path.cwd()
    img_files, events, masks = _get_files(subject="sub-01", data_dir=datadir)

    stats_imgs = []
    for img, event, mask in zip(img_files, events, masks):
        stats_img = _gen_stats_img(img, event, mask)
        stats_imgs.append(stats_img)

    ffx_contrast, ffx_variance, ffx_stat, ffx_zscore = compute_fixed_effects(
        [simg["effect_size"] for simg in stats_imgs],
        [simg["effect_variance"] for simg in stats_imgs],
        return_z_score=True,
    )
    plotting.plot_stat_map(
        ffx_zscore,
        bg_img=image.mean_img(img_files[0]),
        threshold=3.0,
        display_mode="z",
        cut_coords=3,
        black_bg=True,
        title="hit-correct_rej",
    )
    plt.show()

    # from https://stackoverflow.com/a/48819434
    # X = tools.add_constant(X1)
    # pd.Series([stats.outliers_influence.variance_inflation_factor(X1.values, i)
    #                for i in range(X1.shape[1])],
    #               index=X1.columns)
