from pathlib import Path

import click
import numpy as np
import pandas as pd
import nibabel as nib
from nilearn import glm, plotting
from nilearn.glm.first_level import FirstLevelModel
from nilearn.glm.contrasts import compute_fixed_effects
from nilearn.interfaces.fmriprep import load_confounds_strategy


def _label_cond(row):
    """
    Parameters
    ----------
    row : pd.Series

    # TODO : Double-check that these are being correctly generated
    """
    view_cond, _ = row["subcondition"].split("-", 1)

    if not row["error"] and view_cond == "unseen":
        cond = "correct_rej"
    elif not row["error"] and view_cond == "seen":
        cond = "hit"
    elif row["error"] is True and view_cond == "unseen":
        cond = "false_alarm"
    elif row["error"] is True and view_cond == "seen":
        cond = "miss"
    else:
        cond = pd.NA
    return cond


def _label_subcond(row):
    """
    Parameters
    ----------
    row : pd.Series

    # TODO : Double-check that these are being correctly generated
    """
    view_cond, pres_cond = row["subcondition"].split("-", 1)
    if "-" in pres_cond:
        pres_cond = pres_cond.split("-")[-1]
    if not row["error"] and view_cond == "unseen":
        cond = "correct_rej"
    elif not row["error"] and view_cond == "seen":
        if pres_cond == "within":
            cond = "hit-within"
        elif pres_cond == "between":
            cond = "hit-between"
    elif row["error"] is True and view_cond == "unseen":
        if pres_cond == "within":
            cond = "false_alarm-within"
        elif pres_cond == "between":
            cond = "false_alarm-between"
    elif row["error"] is True and view_cond == "seen":
        if pres_cond == "within":
            cond = "miss-within"
        elif pres_cond == "between":
            cond = "miss-between"
    else:
        cond = pd.NA
    return cond


def _get_files(subject, data_dir):
    """
    Parameters
    ----------
    subject : str
        CNeuroMod subject for analysis. Must be in
        ['sub-01', 'sub-02', 'sub-03', 'sub-06']
    data_dir : str or Pathlike
        Location on disk with CNeuroMod things.fmriprep dataset.
        Assumes this has previously been installed with datalad.

    Returns
    -------
    img_files : list
        List of fMRIPrep-preprocessed NifTI image files for the
        given subject, T1w space
    events : list
        List of events files for each subject, used to generate
        design matrices
    masks : list
        List of brain masks generated by fMRIPrep for each run,
        T1w space
    """
    img_files = sorted(
        Path(data_dir, "things.fmriprep", subject).rglob(
            "*space-T1w_desc-preproc_bold.nii.gz"
        )
    )
    masks = sorted(
        Path(data_dir, "things.fmriprep", subject).rglob(
            "*space-T1w_desc-brain_mask.nii.gz"
        )
    )
    events = sorted(
        Path(data_dir, "things.fmriprep", "sourcedata", "things", subject).rglob(
            "*events.tsv"
        )
    )

    # drop ses-01 / ses-001 from images, masks, events
    img_files = list(filter(lambda i: ("ses-01" not in str(i)), img_files))
    masks = list(filter(lambda m: ("ses-01" not in str(m)), masks))
    events = list(filter(lambda e: ("ses-01" not in str(e)), events))

    if subject == "sub-01":
        # exceptionally sub-01, ses-30, run-1 had no responses ;
        # need to additionally filter these out
        img_files = list(
            filter(
                lambda i: ("sub-01_ses-30_task-things_run-1" not in str(i)), img_files
            )
        )
        masks = list(
            filter(lambda m: ("sub-01_ses-30_task-things_run-1" not in str(m)), masks)
        )
        events = list(
            filter(lambda e: ("sub-01_ses-30_task-things_run-01" not in str(e)), events)
        )

    if subject == "sub-06":
        # exceptionally  sub-06, ses-08, run-6 was dropped after preprocessing ;
        # not yet removed from the full dataset, so filter accordingly
        img_files = list(
            filter(
                lambda i: ("sub-06_ses-08_task-things_run-6" not in str(i)), img_files
            )
        )
        masks = list(
            filter(lambda m: ("sub-06_ses-08_task-things_run-6" not in str(m)), masks)
        )
        events = list(
            filter(lambda e: ("sub-06_ses-08_task-things_run-06" not in str(e)), events)
        )

    return img_files, events, masks


def _gen_fmri_glm(
    img, event, mask, top_level=False, t_r=1.49, smoothing_fwhm=5, return_x_matrix=False
):
    """
    Parameters
    ----------
    img : str or Pathlike
    event : str or Pathlike
    mask : str or Pathlik
    t_r : float
        Default 1.49
    smoothing_fwhm : int
        Default 5
    return_x_matrix : Bool
        Default False

    Returns
    -------
    stats_img : dict
    design_matrix : pd.DataFrame, optional
    """
    # load in events files and create memory conditions
    # based on performance
    try:
        df = pd.read_csv(event, sep="\t")
        if top_level:
            df["memory_cond"] = df.apply(_label_cond, axis=1)
        else:
            df["memory_cond"] = df.apply(_label_subcond, axis=1)
        memory_events = pd.DataFrame(
            {"trial_type": df.memory_cond, "onset": df.onset, "duration": df.duration}
        )

        # n_compcor chosen from
        # https://www.frontiersin.org/files/Articles/54426/fnins-07-00247-HTML/image_m/fnins-07-00247-g002.jpg
        confounds, _ = load_confounds_strategy(
            str(img),
            denoise_strategy="compcor",
            compcor="temporal_anat_separated",
            n_compcor=5,
        )

        n_scans = nib.load(img).shape[-1]
        frame_times = np.arange(n_scans) * t_r
        minutes_scanned = (n_scans * t_r) / 60

        # generate design matrices
        # TODO: Select sensible choices here
        design_matrix = glm.first_level.make_first_level_design_matrix(
            frame_times=frame_times,
            events=memory_events,
            drift_model="polynomial",
            drift_order=round(minutes_scanned / 2),
            add_regs=confounds,
            add_reg_names=confounds.columns,
            hrf_model="spm",
        )

        fmri_glm = FirstLevelModel(
            t_r=t_r, mask_img=mask, smoothing_fwhm=smoothing_fwhm
        )
        fmri_glm = fmri_glm.fit(img, design_matrices=design_matrix)

    except (FileNotFoundError, ValueError) as e:
        warn_msg = (
            "Not all files can be loaded. Please ensure that files have been "
            "first downloaded with datalad."
        )
        raise UserWarning(warn_msg)

    if return_x_matrix:
        return fmri_glm, design_matrix
    else:
        return fmri_glm


def _gen_stats_img(img_files, events, masks, contrast_dict, data_dir, verbose=True):
    """
    Parameters
    ----------
    img_files : itr
    events : itr
    masks : itr
    contrast_dict : dict
    data_dir : str or pathlike
    verbose : bool
    """
    stats_imgs = []
    for img, event, mask in zip(img_files, events, masks):

        # recreate this ; will need sub_name regardless
        sub_name, ses, _, run, _ = event.name.split("_")

        fmri_glm, xmatrix = _gen_fmri_glm(
            img, event, mask, top_level=contrast_dict["top_level"], return_x_matrix=True
        )
        if verbose:
            if contrast_dict["top_level"]:
                xmatrix_name = f"{sub_name}_{ses}_task-things_{run}_design.png"
            else:
                xmatrix_name = f"{sub_name}_{ses}_task-things_{run}_subcond_design.png"

            out_name = Path(
                data_dir,
                sub_name,
                "glm",
                "design_matrices",
                xmatrix_name,
            )
            # explicitly make parent directories, if they don't exist
            out_name.parent.mkdir(parents=True, exist_ok=True)
            plotting.plot_design_matrix(
                xmatrix,
                output_file=out_name,
            )

        contrast_val = (xmatrix.columns == contrast_dict["condition_a"]) * 1.0 - (
            xmatrix.columns == contrast_dict["condition_b"]
        )
        stats_img = fmri_glm.compute_contrast(contrast_val, output_type="all")
        stats_imgs.append(stats_img)

    ffx_contrast, ffx_variance, ffx_stat, ffx_zscore = compute_fixed_effects(
        [simg["effect_size"] for simg in stats_imgs],
        [simg["effect_variance"] for simg in stats_imgs],
        return_z_score=True,
    )

    for stat_name, ffx_output in zip(
        ["t", "variance", "effect", "z"],
        [ffx_contrast, ffx_variance, ffx_stat, ffx_zscore],
    ):
        out_name = Path(
            data_dir,
            sub_name,
            "glm",
            f"{sub_name}_task-things_space-T1w_contrast-{contrast_dict['contrast_name']}_stat-{stat_name}_statmap.nii.gz",
        )
        # explicitly make parent directories, if they don't exist
        out_name.parent.mkdir(parents=True, exist_ok=True)
        ffx_output.to_filename(out_name)
    return


@click.command()
@click.option("--sub_name", default="sub-01", help="Subject name")
@click.option(
    "--data_dir", default="/Users/emdupre/Desktop/things-glm", help="Data directory."
)
@click.option(
    "--verbose", is_flag=True, help="Whether to return generated design matrices."
)
def main(sub_name, data_dir, verbose):
    """ """
    img_files, events, masks = _get_files(subject=sub_name, data_dir=data_dir)

    contrast_dicts = [
        {
            "contrast_name": "HitvCorrectRej",
            "condition_a": "hit",
            "condition_b": "correct_rej",
            "top_level": True,
        },
        {
            "contrast_name": "HitWithinvCorrectRej",
            "condition_a": "hit-within",
            "condition_b": "correct_rej",
            "top_level": False,
        },
        {
            "contrast_name": "HitBtwnvCorrectRej",
            "condition_a": "hit-between",
            "condition_b": "correct_rej",
            "top_level": False,
        },
    ]

    for contrast_dict in contrast_dicts:
        _gen_stats_img(
            img_files, events, masks, contrast_dict, data_dir, verbose=verbose
        )

    return

    # from https://stackoverflow.com/a/48819434
    # X = tools.add_constant(X1)
    # pd.Series([stats.outliers_influence.variance_inflation_factor(X1.values, i)
    #                for i in range(X1.shape[1])],
    #               index=X1.columns)


if __name__ == "__main__":
    main()
